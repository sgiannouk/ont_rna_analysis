###Stavros Giannoukakos### 

### conda activate pycoQC

#Version of the program
__version__ = "0.1.0"

import argparse
import subprocess
import shutil, time, glob, sys, os, re

# raw_data_dir =  "/shared/projects/silvia_ont_umc/all_rna_sample2/20190604_1354_MN29521_FAK43904_3bcfbe09"
raw_data_dir =  "/shared/projects/silvia_ont_umc/mrna_sample3/sample_3/20190611_1508_MN29521_FAK43817_4ea54369"
refGenomeGRCh38 = "~/playground/progs/reference_files/reference_genome/GRCh38_primAssembly/GRCh38_primary_assembly_genome.fa"
refTranscGRCh38 = "~/playground/progs/reference_files/reference_transcriptome/ensembl_cdna_ncrna/GRCh38_cdna_ncrna.fasta"


refAnnot = "~/playground/progs/reference_files/gene_annotation/gencode.v29.primary_assembly.annotation.gtf"
reference_annotation_bed = "/home/stavros/playground/progs/reference_files/gene_annotation/hg38_Gencode_V28.bed"
refSeqGRCh38 = "~/playground/progs/reference_files/gene_annotation/RefSeq/Homo_sapiens.GRCh38.96.chr_patch_hapl_scaff.gff"


usage = "ont_analysis [options]"
epilog = " -- June 2019 | Stavros Giannoukakos -- "
description = "DESCRIPTION"

parser = argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter, usage=usage, description=description, epilog=epilog)
# Number of threads/CPUs to be used
parser.add_argument('-th', '--threads', dest='threads', default=str(20), metavar='', 
                	help="Number of threads to be used in the analysis")
# Display the version of the pipeline 
parser.add_argument('-v', '--version', action='version', version='%(prog)s {0}'.format(__version__))
# Get the options and return them
args = parser.parse_args()

current_dir = os.getcwd()

# Main folder hosting the analysis
analysis_dir = os.path.join(current_dir, "analysis")
prepr_dir = os.path.join(analysis_dir, "preprocessed_data")
alignments_dir = os.path.join(analysis_dir, "alignments")
reports_dir = os.path.join(analysis_dir, "reports")
postanalysis_dir = os.path.join(analysis_dir, "postanalysis")

def quality_control():
	if not os.path.exists(reports_dir): os.makedirs(reports_dir)

	seq_summary_file = [sum_file for sum_file in glob.glob(os.path.join(raw_data_dir, "*/*_sequencing_summary.txt"))][0]
	sample_id = raw_data_dir.split("/")[4].split("_")[-1]

	
	print("pycoQC - Quality Control of the raw data: in progress ..")
	pycoQC = " ".join([
	"pycoQC",  # Call pycoQC
	"--summary_file", seq_summary_file,  # Input of <sequencing_summary> generated by Albacore1.0.0 / Guppy 2.1.3+
	"--html_outfile", os.path.join(reports_dir, "{0}_pycoQC_report.html".format(sample_id)),  # Create the report in the reports directory
	"--report_title", "\"{0} quality control report\"".format(sample_id),  # A title to be used in the html report
	"2>>", os.path.join(reports_dir, "pycoQC-report.txt")])
	subprocess.run(pycoQC, shell=True)

	print("nanoPlot - Quality Control of the raw data: in progress ..")
	nanoPlot = " ".join([
	"NanoPlot",  # Call pycoQC
	"--threads", str(args.threads),  # Number of threads to be used by the script
	"--summary", seq_summary_file,  # Input of <sequencing_summary> generated by Albacore1.0.0 / Guppy 2.1.3+
	"--color saddlebrown",  # Color for the plots
	"--colormap PuBuGn",  # Colormap for the heatmap
	"--prefix", os.path.join(reports_dir, "{0}_rawReadsQC_".format(sample_id)),  # Create the report in the reports directory
	"--format png",  # Output format of the plots
	"--dpi 900", # Set the dpi for saving images in high resolution
	"2>>", os.path.join(reports_dir, "nanoPlot-report.txt")])
	subprocess.run(nanoPlot, shell=True)
	# preprocessing_raw_data()
	return

def preprocessing_raw_data():
	if not os.path.exists(prepr_dir): os.makedirs(prepr_dir)
	raw_data = [sum_file for sum_file in glob.glob(os.path.join(raw_data_dir, "fastq_pass/*.fastq.gz"))]	

	for file in raw_data[0:5]:
		file_name = os.path.basename(file.split(".")[0]) 
		porechop = " ".join([
		"porechop",  # Call porechop to trim adapters
		"--threads", str(args.threads),  # Number of threads to be used by the script
		"--format fastq.gz",  # Output as compressed fastq files
		"--input", file,  # FASTQ of input reads
		"--output", os.path.join(prepr_dir, "{0}.tr.fastq.gz".format(file_name)),  # Filename for FASTQ of trimmed reads
		"--verbosity 3",  # Level of progress information
		"2>>", os.path.join(reports_dir, "porechop-report.txt")])
		subprocess.run(porechop, shell=True)
	return

def alignment_against_ref():
	if not os.path.exists(alignments_dir): os.makedirs(alignments_dir)

	raw_data = [sum_file for sum_file in glob.glob(os.path.join(raw_data_dir, "fastq_pass/*.fastq.gz"))]
	sample_id = raw_data_dir.split("/")[4].split("_")[-1]

	for i, files in enumerate(raw_data[0:1], 1):
		file_name = os.path.basename(files.split(".")[0])
		print("{0}/{1} | minimap2 - Mapping {2} against the reference genome: in progress ..".format(i, len(raw_data), file_name))
		minimap2_genome = " ".join([
		"~/playground/progs/minimap2-2.17_x64-linux/minimap2",  # Call minimap2 (v2.17-r941)
		"-t", str(args.threads),  # Number of threds to use
		"-ax splice",   # Long-read spliced alignment mode and output in SAM format (-a)
		"-k 14",  # k-mer size
		"-uf",  # Find canonical splicing sites GT-AG - f: transcript strand
		"--secondary=no",
		# "-o", os.path.join(alignments_dir, "{0}.genome.paf".format(file_name)),
		refGenomeGRCh38,  # Inputting the reference genome
		files,  # Input .fastq.gz file
  		"|", "samtools sort",  # Calling 'samtools sort' to sort the output alignment file
  		"--threads", str(args.threads),  # Number of threads to be used by 'samtools sort'
  		"--output-fmt BAM",  # Output in BAM format
  		"-o", os.path.join(alignments_dir, "{0}.genome.bam".format(file_name)),  # Sorted output  BAM file
		"2>>", os.path.join(reports_dir, "minimap2_genome-report.txt")])  # Directory where all FastQC and Cutadapt reports reside
		subprocess.run(minimap2_genome, shell=True)

		print("{0}/{1} | minimap2 - Mapping {2} against the reference transcriptome: in progress ..".format(i, len(raw_data), file_name))		
		minimap2_transcriptome = " ".join([
		"~/playground/progs/minimap2-2.17_x64-linux/minimap2",  # Call minimap2 (v2.17-r941)
		"-t", str(args.threads),  # Number of threds to use
		"-ax map-ont",
		"-k 14",  # k-mer size
		"--secondary=no",  # Higher junction accuracy
		# "-o", os.path.join(alignments_dir, "{0}.transcriptome.paf".format(file_name)),
		refTranscGRCh38,  # Inputting the reference genome
		files,  # Input .fastq.gz file
		"|", "samtools sort",  # Calling 'samtools sort' to sort the output alignment file
  		"--threads", str(args.threads),  # Number of threads to be used by 'samtools sort'
  		"--output-fmt BAM",  # Output in BAM format
  		"-o", os.path.join(alignments_dir, "{0}.transcriptome.bam".format(file_name)), "-",  # Sorted output  BAM file
		"2>>", os.path.join(reports_dir, "minimap2_transcriptome-report.txt")])  # Directory where all FastQC and Cutadapt reports reside
		subprocess.run(minimap2_transcriptome, shell=True)
	return

def mapping_qc():

	if not os.path.exists(postanalysis_dir): os.makedirs(postanalysis_dir)
	aligned_data = [sum_file for sum_file in glob.glob(os.path.join(alignments_dir, "*.bam"))]
	genome_alignments = [sum_file for sum_file in glob.glob(os.path.join(alignments_dir, "*.genome.bam"))]
	transcriptome_alignments = [sum_file for sum_file in glob.glob(os.path.join(alignments_dir, "*.transcriptome.bam"))]
	sample_id = raw_data_dir.split("/")[4].split("_")[-1]

	## EXPORTING ALIGNMENT STATS
	print("RSeQC & Picard - Generating post-alignment stats: in progress ..")
	for file in aligned_data:
		file_name = os.path.basename(file).split(".")[0]
		aligned_to = ["transcriptome", "genome"][file.endswith(".genome.bam")]
		ref_file = [refTranscGRCh38, refGenomeGRCh38][file.endswith(".genome.bam")]
		
		# BAM stats
		bam_stat = ' '.join([
		"bam_stat.py",
		"-i", file,  # Input BAM file
		"> {0}/{1}_bamstat.{2}.txt".format(postanalysis_dir, file_name, aligned_to),  # Output file
		# "2>>", os.path.join(postanalysis_dir, "{0}_{1}_bamstats-report.txt".format(file_name, aligned_to))
		])
		subprocess.run(bam_stat, shell=True)

		# Picard CollectAlignmentSummaryMetrics
		CollectAlignmentSummaryMetrics = ' '.join([
		"picard CollectAlignmentSummaryMetrics",  # Call picard CollectAlignmentSummaryMetrics
		"INPUT= {0}".format(file),  # Input BAM file
		"OUTPUT= {0}/{1}_alignment_metrics.{2}.txt".format(postanalysis_dir, file_name, aligned_to),  # Output
		"REFERENCE_SEQUENCE= {0}".format(ref_file),  # Reference sequence file
		"2>>", os.path.join(postanalysis_dir, "{0}_{1}_CollectAlignmentSummaryMetrics-report.txt".format(file_name, aligned_to))])
		subprocess.run(CollectAlignmentSummaryMetrics, shell=True) 

		if file.endswith(".genome.bam"):
			# BAM read distribution
			read_distribution = ' '.join([
			"read_distribution.py", 
			"-i", file,  # Input BAM file
			"-r", reference_annotation_bed,
			"> {0}/{1}.{2}.fragSize".format(postanalysis_dir, file_name, aligned_to),  # Output file
			# "2>>", os.path.join(postanalysis_dir, "{0}_{1}_read_distribution-report.txt".format(file_name, aligned_to))
			])
			subprocess.run(read_distribution, shell=True)

			# Check the strandness of the reads
			strandness = ' '.join([
			"infer_experiment.py",  # Call samtools flagstat
			"-i", file,  # Input BAM file
			"-r", reference_annotation_bed,
			"> {0}/{1}_strandness.{2}.txt".format(postanalysis_dir, file_name, aligned_to),  # Output file
			# "2>>", os.path.join(postanalysis_dir, "{0}_{1}_strandness-report.txt".format(file_name, aligned_to))
			])
			subprocess.run(strandness, shell=True)

			# Check duplicate reads
			duplicate_reads = ' '.join([
			"read_duplication.py",  # Call samtools flagstat
			"-i", file,  # Input BAM file
			"-o", "{0}/{1}_duplicates.{2}".format(postanalysis_dir, file_name, aligned_to),  # Output file
			# "2>>", os.path.join(postanalysis_dir, "{0}_{1}_duplicate_reads-report.txt".format(file_name, aligned_to))
			])
			subprocess.run(duplicate_reads, shell=True)

			# Number of reads mapped to each chromosome
			mapping_pos = ' '.join([
			"samtools idxstats",  # Call samtools flagstat
			"--threads", args.threads,
			file,  # Input BAM file
			"> {0}/{1}_mapping_position.{2}.txt".format(postanalysis_dir, file_name, aligned_to),  # Output file
			# "2>>", os.path.join(postanalysis_dir, "{0}_{1}_mapping_position-report.txt".format(file_name, aligned_to))
			])
			subprocess.run(mapping_pos, shell=True)
		
	# Gene body coverage
	gene_coverage = ' '.join([
	"geneBody_coverage.py",  # Call samtools flagstat
	"-r", reference_annotation_bed,
	"-i", ",".join(genome_alignments),  # Input BAM file
	"-o", "{0}/gene_coverage.{1}".format(postanalysis_dir, aligned_to),  # Output file
	# "2>>", os.path.join(postanalysis_dir, "{0}_{1}_mapping_position-report.txt".format(file_name, aligned_to))
	])
	subprocess.run(gene_coverage, shell=True)

	# Post Alignment QC
	print("nanoPlot - Quality Control of the genome aligned data: in progress ..")
	nanoPlot_gn = " ".join([
	"NanoPlot",  # Call pycoQC
	"--threads", str(args.threads),  # Number of threads to be used by the script
	"--color saddlebrown",  # Color for the plots
	"--colormap PuBuGn",  # Colormap for the heatmap
	"--prefix", os.path.join(postanalysis_dir, "{0}_gnQC_".format(sample_id)),  # Create the report in the reports directory
	"--format png",  # Output format of the plots
	"--dpi 900", # Set the dpi for saving images in high resolution
	"--bam", " ".join(genome_alignments),  # Input bam files
	# "2>>", os.path.join(postanalysis_dir, "nanoPlot_gnQC_alignment-report.txt")
	])
	subprocess.run(nanoPlot_gn, shell=True)
	
	
	print("nanoPlot - Quality Control of the transcriptome aligned data: in progress ..")
	nanoPlot_tr = " ".join([
	"NanoPlot",  # Call pycoQC
	"--threads", str(args.threads),  # Number of threads to be used by the script
	"--bam", " ".join(transcriptome_alignments),  # Input bam files
	"--color saddlebrown",  # Color for the plots
	"--colormap PuBuGn",  # Colormap for the heatmap
	"--prefix", os.path.join(postanalysis_dir, "{0}_trQC_".format(sample_id)),  # Create the report in the reports directory
	"--format png",  # Output format of the plots
	"--dpi 900", # Set the dpi for saving images in high resolution
	# "2>>", os.path.join(postanalysis_dir, "nanoPlot_trQC_alignment-report.txt")
	])
	subprocess.run(nanoPlot_tr, shell=True)

	print("Pistis - Quality Control of the raw and genome aligned data: in progress ..")
	for aligned_files in genome_alignments:
		sample_id = os.path.basename(aligned_files).split(".")[0]
		# Indexing BAM files
		samtools_index = " ".join([
		"samtools index",
		"-@", str(args.threads),
		aligned_files])
		subprocess.run(samtools_index, shell=True)
		# Run Pistis QC
		pistis = " ".join([
		"pistis",
		"--downsample 0",
		"--fastq", os.path.join(raw_data_dir, "fastq_pass/{0}.fastq.gz".format(sample_id)),
		"--bam", aligned_files,  # Input bam files
		"--output", os.path.join(postanalysis_dir, "{0}_PistisQC.pdf".format(sample_id)),
		# "2>>", os.path.join(postanalysis_dir, "pistis_QCalignment-report.txt")
		])
		subprocess.run(pistis, shell=True)
	return

def generate_expression_matrices():
	genome_alignments = [sum_file for sum_file in glob.glob(os.path.join(alignments_dir, "*.genome.bam"))]
	print("FeatureCounts - Counting reads from the genome aligned data: in progress ..")
	featureCounts_gn = " ".join([
	"featureCounts",  # Call featureCounts
	"-T", str(args.threads),  # Number of threads to be used by the script
	"-a", refAnnot,  # Annotation file in GTF/GFF format
	"-L",  # Count long reads such as Nanopore and PacBio reads
	"-o", os.path.join(postanalysis_dir, "genome_alignments_sum.tab"),  # Output file including read counts
	" ".join(genome_alignments),  # Input bam files
	# "2>>", os.path.join(reports_dir, "featureCounts_genome_summary-report.txt")
	]) 
	subprocess.run(featureCounts_gn, shell=True)
	
	print("Exporting the (genomic) expression matrix: in progress ..")
	subprocess.run("cut -f1,7,8,9,10,11,12 {0}/genome_alignments_sum.tab > {0}/featureCounts_expression_matrix.txt".format(postanalysis_dir), shell=True)
	subprocess.run("sed -i \'1d\' {0}/featureCounts_expression_matrix.txt".format(postanalysis_dir), shell=True)  # Removing first line of the expression matrix

	# transcriptome_alignments = [sum_file for sum_file in glob.glob(os.path.join(alignments_dir, "*.transcriptome.bam"))]
	# print("Cufflinks - Counting reads from the transcriptome aligned data: in progress ..")
	# for file in transcriptome_alignments:
	# 	cufflinks = " ".join([
	# 	"cufflinks",  # Call pycoQC
	# 	"--num-threads", str(args.threads),  # Number of threads to be used by the script
	# 	"--output-dir", postanalysis_dir,  # Output directory
	# 	"--GTF", refAnnot,  # Annotation file in GTF format
	# 	file,
	# 	"2>>", os.path.join(reports_dir, "cufflinks_transcriptome_summary-report.txt")])
	# 	subprocess.run(cufflinks, shell=True)
	
	# print("Exporting the (transcriptomic) expression matrix: in progress ..")
	# subprocess.run("ls {0}/*.txt > {1}/cufflinks_outputs.txt".format(args.threads), shell=True)
	# subprocess.run("cuffmerge --num-threads {0} --ref-gtf {1} --ref-sequence {2} -o {3} {3}/cufflinks_outputs.txt"\
	# 							   .format(args.threads, refAnnot, refGenomeGRCh38, postanalysis_dir), shell=True)
	return

def summary():
	figures_dir = os.path.join(reports_dir, "figures")
	if not os.path.exists(figures_dir): os.makedirs(figures_dir)

	os.system('mv {0}/*.png {1}'.format(reports_dir, figures_dir))  # Moving png files to "figures" directory
	for path, subdir, folder in os.walk(reports_dir):
		for name in folder:
			file = os.path.join(path, name)
			if os.stat(file).st_size == 0:  
				print("Removing:\t", file)  
				os.remove(file)

	print("multiQC - Summing all QC reports: in progress ..")
	multiQC = " ".join([
	"multiqc",  # Call MultiQC
	"--quiet",  # Print only log warnings
	"--outdir", postanalysis_dir,  # Create report in the FastQC reports directory
	"--filename", "post-alignment_summarised_report",  # Name of the output report 
	postanalysis_dir,  # Directory where all FastQC and Cutadapt reports reside
	"2>>", os.path.join(postanalysis_dir, "post-alignment_multiQC-report.txt")])  # Output multiQC report
	subprocess.run(multiQC, shell=True)

	## REMOVING UNNECESSARY FILES & REPORTS
	for path, subdir, folder in os.walk(postanalysis_dir):
		for name in folder:
			file = os.path.join(path, name)
			if os.stat(file).st_size == 0 or\
			(name.endswith("multiQC-report.txt") and os.stat(file).st_size == 583) or\
			(name.endswith("bamstats-report.txt") and os.stat(file).st_size == 24) or\
	  		(name.endswith("ribution-report.txt") and os.stat(file).st_size == (255 or 256)) or\
	  		(name.endswith("Metrics-report.txt") and os.stat(file).st_size == 3):
				os.remove(file)
	os.system('rm -r {0}/*summarised_report_data'.format(postanalysis_dir))
	return

def main():
	
	# quality_control()

	# alignment_against_ref()

	mapping_qc()

	generate_expression_matrices()

	summary()

if __name__ == "__main__": main()